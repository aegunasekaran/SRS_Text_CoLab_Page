{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "!pip install PyMuPDF\n",
        "!pip install python-docx\n",
        "!pip install nltk\n",
        "!pip install pandas\n",
        "\n",
        "# File Upload Interface\n",
        "from google.colab import files\n",
        "import fitz # PyMuPDF PDF Handeling interface\n",
        "import docx # python-docx handeling interface\n",
        "import nltk\n",
        "import pandas as pd # Display output in a Table\n",
        "\n",
        "# NLTK for sentence tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Interactive Data Table\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "LPNvn6sqm6Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File Upload\n",
        "def upload_files():\n",
        "  uploaded = files.upload()\n",
        "  return uploaded\n",
        "\n",
        "uploaded_files = upload_files()\n",
        "\n",
        "# Extract from PDF\n",
        "def extract_text_from_pdf(file_path):\n",
        "  doc = fitz.open(file_path)\n",
        "  text = \"\"\n",
        "  for page_num in range(doc.page_count):\n",
        "    page = doc.load_page(page_num)\n",
        "    all_text = page.get_text()\n",
        "    text += all_text\n",
        "  return text\n",
        "\n",
        "# Extract from Word\n",
        "def extract_text_from_word(file_path):\n",
        "  doc = docx.Document(file_path)\n",
        "  text = \"\"\n",
        "  for para in doc.paragraphs:\n",
        "    text += para.text + \"\\n\"\n",
        "  return text\n",
        "\n",
        "# Determine file type and extract text\n",
        "import os\n",
        "\n",
        "for file_name in uploaded_files.keys():\n",
        "  file_path = file_name\n",
        "  file_ext = os.path.splitext(file_path)[1].lower()\n",
        "  if file_ext == '.pdf':\n",
        "    text = extract_text_from_pdf(file_path)\n",
        "  elif file_ext == '.docx':\n",
        "    text = extract_text_from_word(file_path)\n",
        "  else:\n",
        "    text = \"Unsupported file type.\"\n",
        "  print(text)\n",
        "\n",
        "# NLTK to segmentation\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Paragraph to Sentence\n",
        "def segment_text_into_sentences(text):\n",
        "  sentences = sent_tokenize(text)\n",
        "  return sentences\n",
        "\n",
        "# Segment extracted text\n",
        "if text != \"Unsupported file type.\":\n",
        "    sentences = segment_text_into_sentences(text)\n",
        "    sentence_data = {'Sentence No': [], 'Sentence': []}\n",
        "    # Output Table\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        sentence_data['Sentence No'].append(i + 1)\n",
        "        sentence_data['Sentence'].append(sentence)\n",
        "\n",
        "    # Convert to pandas DataFrame\n",
        "    df = pd.DataFrame(sentence_data)\n",
        "\n",
        "    # Display the DataFrame\n",
        "    from IPython.display import display\n",
        "    display(df)"
      ],
      "metadata": {
        "id": "AhQ-BnIwm-fT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}